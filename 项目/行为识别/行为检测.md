

***项目介绍：***保险公司业务中涉密区域操作规范检测。在边缘设备nvidia nx上，采用目标分割对单帧图像行为关键信息进行分割，分割后的信息送入时序上进行行为判断，将不合规行为上报到前端界面进行人工审查。

***责任描述：***负责目标分割算法的设计、调优和部署。优化模型结构，提高模型在边缘设备上的推断速度和精度。设计和优化时序上的后处理算法，减少漏检。在边缘设备设计多线程数据处理与批预测，解决并发问题。在实际业务场景中，在nvidia nx下单帧推断速度300ms每帧，批预测达到每秒8帧，行为检出正确率为90%，目前已在中国人寿福建分公司试点。

保险公司业务中涉密区域流程规范检测，通过视频监控，检测工作人员的行为规范，判断是否违规，提高排查的效率。负责合同打印过程中的操作规范、合同快递寄送规范核验以及办公区域的违规行为检测，包括3个场景10种行为检测的模型设计、行为分析后处理算法以及边缘设备部署。制定以语义分割模型检测图像行为，减少数据的标注量，提高模型检测精度；设计了轻量模型结构，在nvidia nx下单帧图像耗时300ms；在边端设备上设计仿tensorflow serving算法，支持多路预测与批预测，在nvidia nx下推断效率达到每秒8帧，减少了一半的推断设备成本；设计了视频流的行为检测算法，减少单帧预测错误带来的影响，提高整个行为的检测准确率。在实际业务场景中，行为检出正确率为96%，目前已在中国人寿福建分公司试点。



Nvidia nx 算力为21 TOPS



框架：tensorflow

语言：python

方法：

小大小的卷积 作为一个小的卷积模块

采用模型分patch 对图像进行下采样。具体为卷积核大小为4 ，步长为4， 通道为4C* n的下采样块

采用（2， 6， 2，2，2 ，2） 作为模型各个尺度的模型块数。下采样128倍可以减少小目标的背景误检。

采用 （h, w, 4c）->  （h, w, 2, 2 ,c）-> （h, 2, w, 2, c） -> (2h,  2w,  c) 实现上采样，减少算力。

现实场景中，采集的图像各式各样，训练的数据集无法全部涵盖，因此需要采用多种方式模拟现实图像， 包括局部噪声、饱和度扩增、色温变换、gamma变换、自适应缩放扩大、图像拉伸、小尺度旋转等等。

难样本挖掘方法，提高检测弱的样本精度。

多尺度训练。最后几个分辨率引出输出头，并使用不同大小的系数作为loss系数，优化整体损失，可以提高没有预训练的小模型精度。

loss 采用 weight  F1-score

```
F1-score = 2*(recall * precision )/(recall + precision)

recall = tp/(tp+fn)     precison = tp/(tp + fp)
```

设计无锚的头部输出，具体为采用中心最大，向外逐步递减的标签设计，再加以后处理后，可以分离同类目标，达到实例分割。

对时序事件进行预测结果平滑后，进行人工规则判定行为。

采用仿tensorflow serving算法，支持多路并发预测和模型热启动，在nvidia nx下推断效率达到每秒8帧+，减少了一半的推断设备成本。



难点

 1.方案选型， 由于边端设备算力的局限，以及行为检测自身的难度，测试了多种方案，包括yolo人体检测加人体图分类， 姿态点估计加点分类等，最后由于信息难以检测，图像少，行为的角度和总类多样，效率等问题，最终根据经验，选择实例分割的方式进行行为检测。首先该方案由于只使用一个模型，不用独立对人进行检测检测后再分割，具有较高的运算速度，其次，由于精细标注，使得模型能够有效获得该行为信息，精度提高，最后配合后处理能有效提取出视频序列的行为。

2.模型设计，采用多头输出，使得不同类目标可以有一定重叠。设计无锚的人头头部输出，具体为采用中心最大，向外逐步递减的标签设计，再加以后处理后，可以分离同类目标，达到实例分割。设计了轻量的模型结构，包括自定义的ssh层，双向relu，可分离卷积块等，在nvidia-nx的可以达到每秒3帧。

3.业务后处理设计上，采用仿tensorflow serving算法，支持多路并发预测和模型热启动，在nvidia nx下推断效率达到每秒8帧+，减少了一半的推断设备成本；设计了多帧预测结果后处理，包括连续窗口预测等，减少单帧预测失效导致的错误，减少行为误检。



1.为什么用边缘设备，因为公司再推软硬件结合。并且方便部署。

2.为什么用目标分割，我的经验告诉我， 越精细的标注模型就越容易学习，精细标注可以使得模型容易学到难识别的行为特征。



# 参考文献 #